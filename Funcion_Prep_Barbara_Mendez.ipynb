{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Funcion_Prep.ipynb.txt",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ99Wv4HWXR3"
      },
      "source": [
        "Importo librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGEfNXKCPtrm",
        "outputId": "76287af1-9ba5-401b-9534-eccb170f3690"
      },
      "source": [
        "\n",
        "\n",
        "# Wikipedia\n",
        "! pip install wikipedia\n",
        "import wikipedia\n",
        "\n",
        "# Corrector ortografico\n",
        "! apt install -qq enchant\n",
        "! apt install myspell-es\n",
        "! pip install pyenchant\n",
        "import enchant\n",
        "\n",
        "from nltk.metrics import edit_distance\n",
        "\n",
        "# NLTK con Google Colab\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "\n",
        "! pip install -U spacy\n",
        "! python -m spacy download es_core_news_lg\n",
        "! python -m spacy download es\n",
        "\n",
        "import spacy\n",
        "import pprint\n",
        "\n",
        "pp = pprint.PrettyPrinter(compact=True)\n",
        "\n",
        "# Tokenizacion:\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#Stop Words:\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#Stemmer:\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Lematizador con Spacy\n",
        "nlp = spacy.load(\"es_core_news_lg\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp37-none-any.whl size=11686 sha256=c0519f75a1c46db556ac94960a44b6ec493a1ca757a5b06cac0675b0d3799713\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  hunspell libreoffice-core | openoffice.org-hunspell | openoffice.org-core\n",
            "  iceape-browser | iceweasel | icedove\n",
            "The following NEW packages will be installed:\n",
            "  myspell-es\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 201 kB of archives.\n",
            "After this operation, 1,004 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 myspell-es all 1.11-14 [201 kB]\n",
            "Fetched 201 kB in 0s (426 kB/s)\n",
            "Selecting previously unselected package myspell-es.\n",
            "(Reading database ... 161104 files and directories currently installed.)\n",
            "Preparing to unpack .../myspell-es_1.11-14_all.deb ...\n",
            "Unpacking myspell-es (1.11-14) ...\n",
            "Setting up myspell-es (1.11-14) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "Collecting pyenchant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/8c/bd224a5db562ac008edbfaf015f5d5c98ea13e745247cd4ab5fc5b683085/pyenchant-3.2.0-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.0\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "Collecting spacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/d8/0361bbaf7a1ff56b44dca04dace54c82d63dad7475b7d25ea1baefafafb2/spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 17.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Collecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n",
            "Collecting pathy>=0.3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/87/5991d87be8ed60beb172b4062dbafef18b32fa559635a8e2b633c2974f85/pathy-0.5.2-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/67/d4002a18e26bf29b17ab563ddb55232b445ab6a02f97bf17d1345ff34d3f/spacy_legacy-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.0.0)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0a/52ae1c659fc08f13dd7c0ae07b88e4f807ad83fb9954a59b0b0a3d1a8ab6/pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1MB 46.1MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/87/decceba68a0c6ca356ddcb6aea8b2500e71d9bc187f148aae19b747b7d3c/thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 56.7MB/s \n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy) (3.4.1)\n",
            "Collecting smart-open<4.0.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/9a/ba2d5f67f25e8d5bbf2fcec7a99b1e38428e83cb715f64dd179ca43a11bb/smart_open-3.0.0.tar.gz (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 41.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Building wheels for collected packages: smart-open\n",
            "  Building wheel for smart-open (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smart-open: filename=smart_open-3.0.0-cp37-none-any.whl size=107098 sha256=3cc95b80eb3888282c94836dd1e5027c3f59fa98da87d773889a6f90530f7a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/88/7c/f06dabd5e9cabe02d2269167bcacbbf9b47d0c0ff7d6ebcb78\n",
            "Successfully built smart-open\n",
            "Installing collected packages: typer, catalogue, smart-open, pathy, spacy-legacy, pydantic, srsly, thinc, spacy\n",
            "  Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Found existing installation: smart-open 5.0.0\n",
            "    Uninstalling smart-open-5.0.0:\n",
            "      Successfully uninstalled smart-open-5.0.0\n",
            "  Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.5.2 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.6 spacy-legacy-3.0.5 srsly-2.4.1 thinc-8.0.3 typer-0.3.2\n",
            "2021-05-04 12:36:29.717568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Collecting es-core-news-lg==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_lg-3.0.0/es_core_news_lg-3.0.0-py3-none-any.whl (569.7MB)\n",
            "\u001b[K     |████████████████████████████████| 569.7MB 27kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-lg==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (20.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (56.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->es-core-news-lg==3.0.0) (1.1.1)\n",
            "Installing collected packages: es-core-news-lg\n",
            "Successfully installed es-core-news-lg-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_lg')\n",
            "2021-05-04 12:37:21.991532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'es' are deprecated. Please use the\n",
            "full pipeline package name 'es_core_news_sm' instead.\u001b[0m\n",
            "Collecting es-core-news-sm==3.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.0.0/es_core_news_sm-3.0.0-py3-none-any.whl (13.9MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.0.0) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (8.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (0.5.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (56.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->es-core-news-sm==3.0.0) (3.0.0)\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.0.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-c8lyUNWdon"
      },
      "source": [
        "Creación de clase para corrección ortográfica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZN_Nv3XSZfS"
      },
      "source": [
        "class SpellingReplacer(object):\n",
        "  def __init__(self, dict_name='es', max_dist=2):\n",
        "    self.spell_dict = enchant.Dict(dict_name)\n",
        "    self.max_dist = max_dist\n",
        "  def replace(self, word):\n",
        "    if self.spell_dict.check(word):\n",
        "      return word\n",
        "    suggestions = self.spell_dict.suggest(word)\n",
        "    if suggestions and edit_distance(word, suggestions[0]) <= self.max_dist:\n",
        "      return suggestions[0]\n",
        "    else:\n",
        "      return word"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq8Vmg2AWnDY"
      },
      "source": [
        "Definición de función con Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ygyJkVIPw6l"
      },
      "source": [
        "def prep_text_stem(text):\n",
        "  replacer = SpellingReplacer()\n",
        "  text = replacer.replace(text)\n",
        "  # Tokenizacion:\n",
        "  text_word = word_tokenize(text, language='spanish')\n",
        "  #Stop Words:\n",
        "  spanish_stops = set(stopwords.words('spanish'))\n",
        "  spanish_stops.update(string.punctuation)\n",
        "  # Sacar stopwords:\n",
        "  text_word_sinsw = [x for x in text_word if x.lower() not in spanish_stops]\n",
        "  #Stemmer:\n",
        "  stemmer = SnowballStemmer('spanish')\n",
        "  stem_text = [stemmer.stem(i) for i in text_word_sinsw]\n",
        "  return stem_text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfl36B62Wryd"
      },
      "source": [
        "Prueba con un ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rej7GWGXU0G5"
      },
      "source": [
        "subject=['Patti Smith']\n",
        "wikipedia.set_lang(\"es\")\n",
        "prueba = wikipedia.page(wikipedia.search(subject)[0]).content"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFro4PfFU6C-",
        "outputId": "1eb495de-de33-4400-c937-3312dfe5e10b"
      },
      "source": [
        "prep_text_stem(prueba)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patrici',\n",
              " 'lee',\n",
              " '«',\n",
              " 'patti',\n",
              " '»',\n",
              " 'smith',\n",
              " 'chicag',\n",
              " '30',\n",
              " 'diciembr',\n",
              " '1946',\n",
              " 'cantant',\n",
              " 'poet',\n",
              " 'estadounidens',\n",
              " 'smith',\n",
              " 'salt',\n",
              " 'fam',\n",
              " 'movimient',\n",
              " 'punk',\n",
              " 'album',\n",
              " 'debut',\n",
              " 'hors',\n",
              " '1975',\n",
              " 'apod',\n",
              " '«',\n",
              " 'madrin',\n",
              " 'punk',\n",
              " '»',\n",
              " '1',\n",
              " '\\u200b',\n",
              " 'traj',\n",
              " 'punt',\n",
              " 'vist',\n",
              " 'femin',\n",
              " 'intelectual',\n",
              " 'music',\n",
              " 'punk',\n",
              " 'convirt',\n",
              " 'artist',\n",
              " 'influyent',\n",
              " 'music',\n",
              " 'rock',\n",
              " 'integr',\n",
              " 'estil',\n",
              " 'poes',\n",
              " 'beat',\n",
              " 'letr',\n",
              " 'introdujeron',\n",
              " 'poes',\n",
              " 'frances',\n",
              " 'sigl',\n",
              " 'xix',\n",
              " 'juventud',\n",
              " 'norteamerican',\n",
              " 'mientr',\n",
              " 'imag',\n",
              " 'androgin',\n",
              " '``',\n",
              " 'femenin',\n",
              " \"''\",\n",
              " 'desaf',\n",
              " 'music',\n",
              " 'disc',\n",
              " 'cancion',\n",
              " 'conoc',\n",
              " '«',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'night',\n",
              " '»',\n",
              " 'coescrib',\n",
              " 'bruc',\n",
              " 'springst',\n",
              " 'lleg',\n",
              " 'puest',\n",
              " 'numer',\n",
              " '13',\n",
              " 'list',\n",
              " 'billboard',\n",
              " 'unid',\n",
              " '1978',\n",
              " 'siend',\n",
              " 'posterior',\n",
              " 'version',\n",
              " 'propi',\n",
              " 'springst',\n",
              " 'keel',\n",
              " '10,000',\n",
              " 'maniacs',\n",
              " 'r.e.m.',\n",
              " 'u2',\n",
              " 'garbag',\n",
              " 'junt',\n",
              " 'screaming',\n",
              " 'femal',\n",
              " 'version',\n",
              " 'eurohous',\n",
              " 'interpret',\n",
              " 'grup',\n",
              " 'italian',\n",
              " 'co.r',\n",
              " '1992',\n",
              " '2005',\n",
              " 'nombr',\n",
              " 'comend',\n",
              " 'orden',\n",
              " 'artes',\n",
              " 'letr',\n",
              " 'franci',\n",
              " '2',\n",
              " '\\u200b',\n",
              " '2007',\n",
              " 'entro',\n",
              " 'salon',\n",
              " 'fam',\n",
              " 'rock',\n",
              " '3',\n",
              " '\\u200b',\n",
              " '2011',\n",
              " 'recib',\n",
              " 'premi',\n",
              " 'music',\n",
              " 'pol',\n",
              " '4',\n",
              " '\\u200b',\n",
              " '2014',\n",
              " 'cantant',\n",
              " 'colabor',\n",
              " 'band',\n",
              " 'sonor',\n",
              " 'noe',\n",
              " 'pelicul',\n",
              " 'dirig',\n",
              " 'darr',\n",
              " 'aronofsky',\n",
              " 'cancion',\n",
              " '«',\n",
              " 'mercy',\n",
              " 'is',\n",
              " '»',\n",
              " 'val',\n",
              " 'nomin',\n",
              " 'glob',\n",
              " 'oro',\n",
              " 'mejor',\n",
              " 'cancion',\n",
              " 'original',\n",
              " 'noviembr',\n",
              " '2019',\n",
              " 'declar',\n",
              " 'visit',\n",
              " 'ilustr',\n",
              " 'montevide',\n",
              " 'uruguay',\n",
              " '5',\n",
              " '\\u200b',\n",
              " '2019',\n",
              " 'recib',\n",
              " 'ademas',\n",
              " 'medall',\n",
              " 'oro',\n",
              " 'bell',\n",
              " 'artes',\n",
              " 'otorg',\n",
              " 'gobiern',\n",
              " 'españ',\n",
              " 'propuest',\n",
              " 'ministr',\n",
              " 'cultur',\n",
              " '6',\n",
              " '\\u200b',\n",
              " '==',\n",
              " 'biograf',\n",
              " '==',\n",
              " '===',\n",
              " 'primer',\n",
              " 'años',\n",
              " '===',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'nac',\n",
              " 'chicag',\n",
              " 'illinois',\n",
              " 'unid',\n",
              " 'madr',\n",
              " 'beverly',\n",
              " 'cantant',\n",
              " 'jazz',\n",
              " 'padr',\n",
              " 'grant',\n",
              " 'trabaj',\n",
              " 'plant',\n",
              " 'multinacional',\n",
              " 'honeywell',\n",
              " 'pas',\n",
              " 'infanci',\n",
              " 'municipi',\n",
              " 'deptford',\n",
              " 'nuev',\n",
              " 'jersey',\n",
              " '7',\n",
              " '\\u200b',\n",
              " '8',\n",
              " '\\u200b',\n",
              " 'cri',\n",
              " 'hij',\n",
              " 'testig',\n",
              " 'jehov',\n",
              " 'dic',\n",
              " 'hab',\n",
              " 'recib',\n",
              " 'fuert',\n",
              " 'educ',\n",
              " 'religi',\n",
              " 'buen',\n",
              " 'educ',\n",
              " 'bibli',\n",
              " 'abandon',\n",
              " 'religion',\n",
              " 'organiz',\n",
              " 'adolescent',\n",
              " 'encontr',\n",
              " 'demasi',\n",
              " 'restrict',\n",
              " 'respect',\n",
              " 'smith',\n",
              " 'escrib',\n",
              " 'años',\n",
              " 'despues',\n",
              " 'estrof',\n",
              " 'inicial',\n",
              " 'version',\n",
              " 'cancion',\n",
              " 'them',\n",
              " '``',\n",
              " 'glori',\n",
              " \"''\",\n",
              " '``',\n",
              " 'jesus',\n",
              " 'mur',\n",
              " 'pec',\n",
              " 'algui',\n",
              " \"''\",\n",
              " 'respuest',\n",
              " 'experient',\n",
              " '9',\n",
              " '\\u200b',\n",
              " 'smith',\n",
              " 'gradu',\n",
              " '1964',\n",
              " 'colegi',\n",
              " 'municipi',\n",
              " 'deptford',\n",
              " 'dificultad',\n",
              " 'econom',\n",
              " 'atraves',\n",
              " 'famili',\n",
              " 'comenz',\n",
              " 'trabaj',\n",
              " 'fabric',\n",
              " 'biciclet',\n",
              " '10',\n",
              " '\\u200b',\n",
              " '===',\n",
              " '1967-1973',\n",
              " 'nuev',\n",
              " 'york',\n",
              " '===',\n",
              " '1967',\n",
              " 'dej',\n",
              " 'estudi',\n",
              " 'universitari',\n",
              " 'glassbor',\n",
              " 'stat',\n",
              " 'teachers',\n",
              " 'colleg',\n",
              " 'mud',\n",
              " 'ciud',\n",
              " 'nuev',\n",
              " 'york',\n",
              " 'alli',\n",
              " 'mientr',\n",
              " 'trabaj',\n",
              " 'joy',\n",
              " 'conoc',\n",
              " 'fotograf',\n",
              " 'robert',\n",
              " 'mapplethorp',\n",
              " 'fotograf',\n",
              " 'hech',\n",
              " 'mapplethorp',\n",
              " 'convert',\n",
              " 'port',\n",
              " 'album',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'group',\n",
              " 'sigu',\n",
              " 'siend',\n",
              " 'amig',\n",
              " 'muert',\n",
              " 'fotograf',\n",
              " '1989',\n",
              " '11',\n",
              " '\\u200b',\n",
              " '1969',\n",
              " 'par',\n",
              " 'herman',\n",
              " 'comenz',\n",
              " 'actu',\n",
              " 'call',\n",
              " 'hac',\n",
              " 'arte',\n",
              " 'performanc',\n",
              " '7',\n",
              " '\\u200b',\n",
              " 'smith',\n",
              " 'regres',\n",
              " 'nuev',\n",
              " 'york',\n",
              " 'viv',\n",
              " 'hotel',\n",
              " 'chelse',\n",
              " 'mapplethorp',\n",
              " 'frecuent',\n",
              " 'club',\n",
              " 'mod',\n",
              " 'ciud',\n",
              " 'cbgb',\n",
              " 'max',\n",
              " \"'s\",\n",
              " 'kans',\n",
              " 'city',\n",
              " 'mism',\n",
              " 'año',\n",
              " 'smith',\n",
              " 'aparec',\n",
              " 'jayn',\n",
              " 'county',\n",
              " 'obra',\n",
              " 'teatr',\n",
              " 'jacki',\n",
              " 'curtis',\n",
              " 'femm',\n",
              " 'fatal',\n",
              " 'ademas',\n",
              " 'miembr',\n",
              " 'proyect',\n",
              " 'poes',\n",
              " 'st',\n",
              " 'mark',\n",
              " 'pas',\n",
              " 'primer',\n",
              " 'años',\n",
              " '70',\n",
              " 'pint',\n",
              " 'escrib',\n",
              " 'actu',\n",
              " 'mism',\n",
              " 'año',\n",
              " 'fotograf',\n",
              " 'loyd',\n",
              " 'ziff',\n",
              " 'recien',\n",
              " 'gradu',\n",
              " 'institut',\n",
              " 'pratt',\n",
              " 'fotograf',\n",
              " 'parej',\n",
              " 'desnud',\n",
              " 'cuart',\n",
              " 'hotel',\n",
              " 'chelse',\n",
              " 'aunqu',\n",
              " 'año',\n",
              " 'retrat',\n",
              " 'hall',\n",
              " 'street',\n",
              " 'dos',\n",
              " 'sesion',\n",
              " 'convirt',\n",
              " 'retrat',\n",
              " 'histor',\n",
              " 'invalu',\n",
              " 'arte',\n",
              " 'norteamerican',\n",
              " 'sigl',\n",
              " 'xx',\n",
              " 'propi',\n",
              " 'lloyd',\n",
              " 'afirm',\n",
              " '``',\n",
              " 'pas',\n",
              " '50',\n",
              " 'años',\n",
              " 'convert',\n",
              " 'document',\n",
              " 'epoc',\n",
              " 'dos',\n",
              " 'artist',\n",
              " 'estadounidens',\n",
              " 'import',\n",
              " 'joven',\n",
              " 'bell',\n",
              " 'ambici',\n",
              " \"''\",\n",
              " '12',\n",
              " '\\u200b',\n",
              " 'fotograf',\n",
              " 'inclu',\n",
              " 'libr',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'just',\n",
              " 'kids',\n",
              " 'saldr',\n",
              " '2009',\n",
              " 'reedit',\n",
              " '2018',\n",
              " 'public',\n",
              " 'desnud',\n",
              " 'mapplethorp',\n",
              " 'peticion',\n",
              " 'propi',\n",
              " 'patti',\n",
              " '13',\n",
              " '\\u200b',\n",
              " '1971',\n",
              " 'hiz',\n",
              " 'performanc',\n",
              " 'obra',\n",
              " 'cowboy',\n",
              " 'mouth',\n",
              " 'sam',\n",
              " 'shepard',\n",
              " '14',\n",
              " '\\u200b',\n",
              " 'colabor',\n",
              " 'allen',\n",
              " 'lani',\n",
              " 'grup',\n",
              " 'rock',\n",
              " 'blu',\n",
              " 'öyster',\n",
              " 'cult',\n",
              " 'grab',\n",
              " 'junt',\n",
              " 'vari',\n",
              " 'cancion',\n",
              " 'colabor',\n",
              " 'smith',\n",
              " 'inclu',\n",
              " '``',\n",
              " 'debbi',\n",
              " 'denis',\n",
              " \"''\",\n",
              " 'poem',\n",
              " '``',\n",
              " 'in',\n",
              " 'remembranc',\n",
              " 'of',\n",
              " 'debbi',\n",
              " 'denis',\n",
              " \"''\",\n",
              " '``',\n",
              " 'car',\n",
              " 'of',\n",
              " 'evil',\n",
              " \"''\",\n",
              " '``',\n",
              " 'fir',\n",
              " 'of',\n",
              " 'unknown',\n",
              " 'origin',\n",
              " \"''\",\n",
              " '``',\n",
              " 'the',\n",
              " 'reveng',\n",
              " 'of',\n",
              " 'ver',\n",
              " 'gemini',\n",
              " \"''\",\n",
              " '``',\n",
              " 'shooting',\n",
              " 'shark',\n",
              " \"''\",\n",
              " 'años',\n",
              " 'smith',\n",
              " 'ejerc',\n",
              " 'period',\n",
              " 'musical',\n",
              " 'escrib',\n",
              " 'rock',\n",
              " 'vari',\n",
              " 'public',\n",
              " 'revist',\n",
              " 'musical',\n",
              " 'creem',\n",
              " '15',\n",
              " '\\u200b',\n",
              " '===',\n",
              " '1974-1979',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'group',\n",
              " '===',\n",
              " '1974',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'hac',\n",
              " 'propi',\n",
              " 'conciert',\n",
              " 'rock',\n",
              " 'inicial',\n",
              " 'guitarr',\n",
              " 'lenny',\n",
              " 'kay',\n",
              " 'posterior',\n",
              " 'band',\n",
              " 'complet',\n",
              " 'form',\n",
              " 'kay',\n",
              " 'bajist',\n",
              " 'ivan',\n",
              " 'kral',\n",
              " 'bat',\n",
              " 'jay',\n",
              " 'dee',\n",
              " 'daugherty',\n",
              " 'pianist',\n",
              " 'richard',\n",
              " 'sohl',\n",
              " 'ivan',\n",
              " 'kral',\n",
              " 'refugi',\n",
              " 'checoslovac',\n",
              " 'huid',\n",
              " '1968',\n",
              " 'tras',\n",
              " 'caid',\n",
              " 'alexand',\n",
              " 'dubček',\n",
              " 'intent',\n",
              " 'reform',\n",
              " 'implant',\n",
              " '``',\n",
              " 'social',\n",
              " 'libert',\n",
              " \"''\",\n",
              " '``',\n",
              " 'regim',\n",
              " 'rostr',\n",
              " 'human',\n",
              " \"''\",\n",
              " 'financi',\n",
              " 'robert',\n",
              " 'mapplethorp',\n",
              " 'band',\n",
              " 'grab',\n",
              " 'prim',\n",
              " 'sencill',\n",
              " '``',\n",
              " 'hey',\n",
              " 'joe',\n",
              " 'piss',\n",
              " 'factory',\n",
              " \"''\",\n",
              " '1974',\n",
              " 'siend',\n",
              " 'car',\n",
              " 'version',\n",
              " 'cancion',\n",
              " 'rock',\n",
              " 'escrit',\n",
              " 'billy',\n",
              " 'roberts',\n",
              " 'previ',\n",
              " 'version',\n",
              " 'jimi',\n",
              " 'hendrix',\n",
              " 'deep',\n",
              " 'purpl',\n",
              " 'añad',\n",
              " 'palabr',\n",
              " 'habl',\n",
              " 'trat',\n",
              " 'secuestr',\n",
              " 'posterior',\n",
              " 'fug',\n",
              " 'patty',\n",
              " 'hearst',\n",
              " '16',\n",
              " '\\u200b',\n",
              " 'car',\n",
              " 'b',\n",
              " 'tem',\n",
              " 'habl',\n",
              " 'frustracion',\n",
              " 'ira',\n",
              " 'sent',\n",
              " 'smith',\n",
              " 'trabaj',\n",
              " 'line',\n",
              " 'ensambl',\n",
              " 'fabric',\n",
              " 'salvacion',\n",
              " 'encontr',\n",
              " 'libr',\n",
              " 'poes',\n",
              " 'frances',\n",
              " 'sigl',\n",
              " 'xix',\n",
              " 'ilumin',\n",
              " 'arthur',\n",
              " 'rimbaud',\n",
              " 'previ',\n",
              " 'rob',\n",
              " 'tiend',\n",
              " '10',\n",
              " '\\u200b',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'group',\n",
              " 'firm',\n",
              " 'sell',\n",
              " 'discograf',\n",
              " 'arist',\n",
              " 'records',\n",
              " 'edit',\n",
              " 'album',\n",
              " 'hors',\n",
              " 'produc',\n",
              " 'john',\n",
              " 'cal',\n",
              " '1975',\n",
              " 'album',\n",
              " 'fusion',\n",
              " 'punk',\n",
              " 'rock',\n",
              " 'poes',\n",
              " 'habl',\n",
              " 'comenz',\n",
              " 'version',\n",
              " 'cancion',\n",
              " '``',\n",
              " 'glori',\n",
              " \"''\",\n",
              " 'van',\n",
              " 'morrison',\n",
              " 'palabr',\n",
              " 'smith',\n",
              " '``',\n",
              " 'jesus',\n",
              " 'mur',\n",
              " 'pec',\n",
              " 'algui',\n",
              " \"''\",\n",
              " 'auster',\n",
              " 'fotograf',\n",
              " 'port',\n",
              " 'hech',\n",
              " 'mapplethorp',\n",
              " 'convirt',\n",
              " 'imag',\n",
              " 'clasic',\n",
              " 'rock',\n",
              " '17',\n",
              " '\\u200b',\n",
              " 'mientr',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'group',\n",
              " 'gir',\n",
              " 'unid',\n",
              " 'europ',\n",
              " 'popular',\n",
              " 'punk',\n",
              " 'comenz',\n",
              " 'aument',\n",
              " 'son',\n",
              " 'crud',\n",
              " 'segund',\n",
              " 'album',\n",
              " 'radi',\n",
              " 'ethiopi',\n",
              " 'reflej',\n",
              " 'cambi',\n",
              " 'recib',\n",
              " 'unas',\n",
              " 'critic',\n",
              " 'bastant',\n",
              " 'mediocr',\n",
              " 'aun',\n",
              " 'asi',\n",
              " 'vari',\n",
              " 'cancion',\n",
              " 'album',\n",
              " 'sobreviv',\n",
              " 'pas',\n",
              " 'tiemp',\n",
              " 'smith',\n",
              " 'aun',\n",
              " 'toc',\n",
              " 'direct',\n",
              " 'hoy',\n",
              " 'dia',\n",
              " '18',\n",
              " '\\u200b',\n",
              " '23',\n",
              " 'ener',\n",
              " '1977',\n",
              " 'mientr',\n",
              " 'encontr',\n",
              " 'gir',\n",
              " 'promocion',\n",
              " 'album',\n",
              " 'smith',\n",
              " 'accident',\n",
              " 'mientr',\n",
              " 'bail',\n",
              " 'caers',\n",
              " 'tarim',\n",
              " 'tamp',\n",
              " 'flor',\n",
              " 'cayend',\n",
              " 'cement',\n",
              " 'fos',\n",
              " 'orquest',\n",
              " 'fractur',\n",
              " 'vari',\n",
              " 'vertebr',\n",
              " 'cervical',\n",
              " '19',\n",
              " '\\u200b',\n",
              " 'accident',\n",
              " 'oblig',\n",
              " 'descans',\n",
              " 'hac',\n",
              " 'rehabilit',\n",
              " 'tiemp',\n",
              " 'repos',\n",
              " 're-energiz',\n",
              " 'reorganiz',\n",
              " 'vid',\n",
              " 'despues',\n",
              " 'recuper',\n",
              " 'patti',\n",
              " 'smith',\n",
              " 'group',\n",
              " 'edit',\n",
              " 'dos',\n",
              " 'album',\n",
              " 'finaliz',\n",
              " 'años',\n",
              " '70',\n",
              " 'east',\n",
              " '1978',\n",
              " 'conten',\n",
              " 'sencill',\n",
              " '``',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'night',\n",
              " \"''\",\n",
              " 'coescrit',\n",
              " 'bruc',\n",
              " 'springst',\n",
              " 'album',\n",
              " 'exit',\n",
              " 'comercial',\n",
              " 'wav',\n",
              " '1979',\n",
              " 'men',\n",
              " 'exit',\n",
              " 'aunqu',\n",
              " 'cancion',\n",
              " '``',\n",
              " 'frederick',\n",
              " \"''\",\n",
              " '``',\n",
              " 'dancing',\n",
              " 'barefoot',\n",
              " \"''\",\n",
              " 'radi',\n",
              " '20',\n",
              " '\\u200b',\n",
              " '===',\n",
              " '1980-1995',\n",
              " 'bod',\n",
              " 'hij',\n",
              " '===',\n",
              " 'lanz',\n",
              " 'wav',\n",
              " 'smith',\n",
              " 'ahor',\n",
              " 'separ',\n",
              " 'allen',\n",
              " 'lani',\n",
              " 'conoc',\n",
              " 'fred',\n",
              " '``',\n",
              " 'sonic',\n",
              " \"''\",\n",
              " 'smith',\n",
              " 'exguitarr',\n",
              " 'band',\n",
              " 'rock',\n",
              " 'detroit',\n",
              " 'michig',\n",
              " 'mc5',\n",
              " 'aquel',\n",
              " 'moment',\n",
              " 'form',\n",
              " 'band',\n",
              " 'sonic',\n",
              " \"'s\",\n",
              " 'rendezvous',\n",
              " 'band',\n",
              " 'ador',\n",
              " 'poes',\n",
              " '``',\n",
              " 'dancing',\n",
              " 'barefoot',\n",
              " \"''\",\n",
              " '``',\n",
              " 'frederick',\n",
              " \"''\",\n",
              " 'album',\n",
              " 'wav',\n",
              " 'ambas',\n",
              " 'dedic',\n",
              " '21',\n",
              " '\\u200b',\n",
              " 'union',\n",
              " 'suscit',\n",
              " 'brom',\n",
              " 'hech',\n",
              " 'sol',\n",
              " 'cas',\n",
              " 'ten',\n",
              " 'cambi',\n",
              " 'apell',\n",
              " '22',\n",
              " '\\u200b',\n",
              " 'hij',\n",
              " 'jackson',\n",
              " 'nac',\n",
              " '1982',\n",
              " 'adel',\n",
              " 'hij',\n",
              " 'jess',\n",
              " 'nac',\n",
              " '1987',\n",
              " 'mayor',\n",
              " 'part',\n",
              " 'años',\n",
              " '80',\n",
              " 'patti',\n",
              " 'retir',\n",
              " 'escen',\n",
              " 'musical',\n",
              " 'viv',\n",
              " 'famili',\n",
              " 'st',\n",
              " 'cla',\n",
              " 'shor',\n",
              " 'nort',\n",
              " 'detroit',\n",
              " 'edit',\n",
              " 'juni',\n",
              " '1988',\n",
              " 'album',\n",
              " 'dream',\n",
              " 'of',\n",
              " 'lif',\n",
              " 'inclu',\n",
              " 'cancion',\n",
              " '``',\n",
              " 'peopl',\n",
              " 'hav',\n",
              " 'the',\n",
              " 'pow',\n",
              " \"''\",\n",
              " 'fred',\n",
              " 'smith',\n",
              " 'mur',\n",
              " '4',\n",
              " 'noviembr',\n",
              " '1994',\n",
              " 'tiemp',\n",
              " 'patti',\n",
              " 'afront',\n",
              " 'inesper',\n",
              " 'muert',\n",
              " 'herman',\n",
              " 'todd',\n",
              " 'teclist',\n",
              " 'band',\n",
              " 'richard',\n",
              " 'sohl',\n",
              " '7',\n",
              " '\\u200b',\n",
              " 'cumpl',\n",
              " 'hij',\n",
              " '14',\n",
              " 'años',\n",
              " 'smith',\n",
              " 'decid',\n",
              " 'volv',\n",
              " 'nuev',\n",
              " 'york',\n",
              " 'amig',\n",
              " 'michael',\n",
              " 'stip',\n",
              " 'r.e.m',\n",
              " 'allen',\n",
              " 'ginsberg',\n",
              " 'conoc',\n",
              " 'primer',\n",
              " 'años',\n",
              " 'nuev',\n",
              " 'york',\n",
              " 'instaron',\n",
              " 'volv',\n",
              " 'hac',\n",
              " 'gir',\n",
              " 'recuper',\n",
              " 'impact',\n",
              " 'ultim',\n",
              " 'acontec',\n",
              " 'embarc',\n",
              " 'pequeñ',\n",
              " 'gir',\n",
              " 'junt',\n",
              " 'bob',\n",
              " 'dylan',\n",
              " 'diciembr',\n",
              " '1995',\n",
              " 'capt',\n",
              " 'libr',\n",
              " 'fotograf',\n",
              " 'michael',\n",
              " 'stip',\n",
              " '14',\n",
              " '\\u200b',\n",
              " '===',\n",
              " '1996-2003',\n",
              " 'retorn',\n",
              " '===',\n",
              " '1996',\n",
              " 'smith',\n",
              " 'volv',\n",
              " 'trabaj',\n",
              " 'band',\n",
              " 'habitual',\n",
              " 'grab',\n",
              " 'gon',\n",
              " 'again',\n",
              " 'inclu',\n",
              " 'tem',\n",
              " '``',\n",
              " 'about',\n",
              " 'boy',\n",
              " \"''\",\n",
              " 'tribut',\n",
              " 'cantant',\n",
              " 'nirvan',\n",
              " 'kurt',\n",
              " 'cobain',\n",
              " 'smith',\n",
              " 'admir',\n",
              " 'cobain',\n",
              " 'declar',\n",
              " 'enfad',\n",
              " 'trist',\n",
              " 'suicidi',\n",
              " 'mism',\n",
              " 'año',\n",
              " 'colabor',\n",
              " 'michael',\n",
              " 'stip',\n",
              " '``',\n",
              " 'e-bow',\n",
              " 'the',\n",
              " 'lett',\n",
              " \"''\",\n",
              " 'cancion',\n",
              " 'r.e.m',\n",
              " 'album',\n",
              " 'new',\n",
              " 'adventur',\n",
              " 'in',\n",
              " 'hi-fi',\n",
              " 'toc',\n",
              " 'direct',\n",
              " '23',\n",
              " '\\u200b',\n",
              " 'despues',\n",
              " 'lanzamient',\n",
              " 'gon',\n",
              " 'again',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDnSTYC_W3l-"
      },
      "source": [
        "Definición de función con Lematización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0NKrlCJW3Sn"
      },
      "source": [
        "def prep_text_lem(text):\n",
        "  replacer = SpellingReplacer()\n",
        "  text = replacer.replace(text)\n",
        "  # Tokenizacion:\n",
        "  text_word = word_tokenize(text, language='spanish')\n",
        "  #Stop Words:\n",
        "  spanish_stops = set(stopwords.words('spanish'))\n",
        "  spanish_stops.update(string.punctuation)\n",
        "  # Sacar stopwords:\n",
        "  text_word_sinsw = [x for x in text_word if x.lower() not in spanish_stops]\n",
        "  #Lematización:\n",
        "  doc = nlp(\" \".join(text_word_sinsw))\n",
        "  lem_text = []\n",
        "  for token in doc:\n",
        "    lem_text.append(token.lemma_)\n",
        "  return lem_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJJ9J56pXddX",
        "outputId": "bda39444-c028-4cbe-d403-6cda60f1f75d"
      },
      "source": [
        "prep_text_lem(prueba)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Patricia',\n",
              " 'Lee',\n",
              " '«',\n",
              " 'Patti',\n",
              " '»',\n",
              " 'Smith',\n",
              " 'Chicago',\n",
              " '30',\n",
              " 'diciembre',\n",
              " '1946',\n",
              " 'cantante',\n",
              " 'poeta',\n",
              " 'estadounidense',\n",
              " 'Smith',\n",
              " 'saltar',\n",
              " 'fama',\n",
              " 'movimiento',\n",
              " 'punk',\n",
              " 'álbum',\n",
              " 'debut',\n",
              " 'Horses',\n",
              " '1975',\n",
              " 'Apodada',\n",
              " '«',\n",
              " 'madrina',\n",
              " 'punk',\n",
              " '»',\n",
              " '1',\n",
              " '\\u200b',\n",
              " 'traer',\n",
              " 'punto',\n",
              " 'visto',\n",
              " 'feminista',\n",
              " 'intelectual',\n",
              " 'música',\n",
              " 'punk',\n",
              " 'convertir',\n",
              " 'artista',\n",
              " 'influyente',\n",
              " 'música',\n",
              " 'rock',\n",
              " 'integrar él',\n",
              " 'estilo',\n",
              " 'poesía',\n",
              " 'beat',\n",
              " 'letra',\n",
              " 'introducir',\n",
              " 'poesía',\n",
              " 'francés',\n",
              " 'siglo',\n",
              " 'xix',\n",
              " 'juventud',\n",
              " 'norteamericano',\n",
              " 'mientras',\n",
              " 'imagen',\n",
              " 'andrógín',\n",
              " '`',\n",
              " '`',\n",
              " 'femenino',\n",
              " \"''\",\n",
              " 'desafiar',\n",
              " 'música',\n",
              " 'disco',\n",
              " 'canción',\n",
              " 'conocido',\n",
              " '«',\n",
              " 'Because',\n",
              " 'the',\n",
              " 'Night',\n",
              " '»',\n",
              " 'coescribir',\n",
              " 'Bruce',\n",
              " 'Springsteen',\n",
              " 'llegar',\n",
              " 'puesto',\n",
              " 'número',\n",
              " '13',\n",
              " 'listo',\n",
              " 'Billboard',\n",
              " 'Unidos',\n",
              " '1978',\n",
              " 'ser',\n",
              " 'posteriormente',\n",
              " 'versionado',\n",
              " 'propio',\n",
              " 'Springsteen',\n",
              " 'Keel',\n",
              " '10.000',\n",
              " 'Maniacs',\n",
              " 'R.E.M.',\n",
              " 'U2',\n",
              " 'Garbage',\n",
              " 'junto',\n",
              " 'Screaming',\n",
              " 'Females',\n",
              " 'versión',\n",
              " 'eurohouse',\n",
              " 'interpretado',\n",
              " 'grupo',\n",
              " 'italiano',\n",
              " 'Co',\n",
              " '.',\n",
              " 'Ro',\n",
              " '1992',\n",
              " '2005',\n",
              " 'nombrado',\n",
              " 'Comendadora',\n",
              " 'Orden',\n",
              " 'Artes',\n",
              " 'Letras',\n",
              " 'Francia',\n",
              " '2',\n",
              " '\\u200b',\n",
              " '2007',\n",
              " 'entrar',\n",
              " 'Salón',\n",
              " 'Fama',\n",
              " 'Rock',\n",
              " '3',\n",
              " '\\u200b',\n",
              " '2011',\n",
              " 'recibir',\n",
              " 'Premio',\n",
              " 'Música',\n",
              " 'Polar',\n",
              " '4',\n",
              " '\\u200b',\n",
              " '2014',\n",
              " 'cantante',\n",
              " 'colaborar',\n",
              " 'banda',\n",
              " 'sonoro',\n",
              " 'Noé',\n",
              " 'película',\n",
              " 'dirigido',\n",
              " 'Darren',\n",
              " 'Aronofsky',\n",
              " 'canción',\n",
              " '«',\n",
              " 'Mercy',\n",
              " 'Is',\n",
              " '»',\n",
              " 'valer',\n",
              " 'nominación',\n",
              " 'Globo',\n",
              " 'Oro',\n",
              " 'mejor',\n",
              " 'canción',\n",
              " 'original',\n",
              " 'noviembre',\n",
              " '2019',\n",
              " 'declarado',\n",
              " 'Visitante',\n",
              " 'Ilustre',\n",
              " 'Montevideo',\n",
              " 'Uruguay',\n",
              " '5',\n",
              " '\\u200b',\n",
              " '2019',\n",
              " 'recibir',\n",
              " 'además',\n",
              " 'Medalla',\n",
              " 'Oro',\n",
              " 'Bellas',\n",
              " 'Artes',\n",
              " 'otorgado',\n",
              " 'Gobierno',\n",
              " 'España',\n",
              " 'propuesto',\n",
              " 'Ministro',\n",
              " 'Cultura',\n",
              " '6',\n",
              " '\\u200b',\n",
              " '=',\n",
              " '=',\n",
              " 'Biografía',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " 'primero',\n",
              " 'año',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'nacer',\n",
              " 'Chicago',\n",
              " 'Illinois',\n",
              " 'Unidos',\n",
              " 'madre',\n",
              " 'Beverly',\n",
              " 'cantante',\n",
              " 'jazz',\n",
              " 'padre',\n",
              " 'Grant',\n",
              " 'trabajar',\n",
              " 'planta',\n",
              " 'multinacional',\n",
              " 'Honeywell',\n",
              " 'Pasó',\n",
              " 'infancia',\n",
              " 'Municipio',\n",
              " 'Deptford',\n",
              " 'Nueva',\n",
              " 'Jersey',\n",
              " '7',\n",
              " '\\u200b',\n",
              " '8',\n",
              " '\\u200b',\n",
              " 'criado',\n",
              " 'hija',\n",
              " 'testigo',\n",
              " 'Jehová',\n",
              " 'decir',\n",
              " 'haber',\n",
              " 'recibir',\n",
              " 'fuerte',\n",
              " 'educación',\n",
              " 'religioso',\n",
              " 'buen',\n",
              " 'educación',\n",
              " 'Biblia',\n",
              " 'abandonar',\n",
              " 'religión',\n",
              " 'organizado',\n",
              " 'adolescencia',\n",
              " 'encontrar él',\n",
              " 'demasiado',\n",
              " 'restrictivo',\n",
              " 'respecto',\n",
              " 'Smith',\n",
              " 'escribir',\n",
              " 'año',\n",
              " 'después',\n",
              " 'estrofa',\n",
              " 'inicial',\n",
              " 'versión',\n",
              " 'canción',\n",
              " 'Them',\n",
              " '`',\n",
              " '`',\n",
              " 'Gloria',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Jesús',\n",
              " 'morir',\n",
              " 'pecado',\n",
              " 'alguien',\n",
              " \"''\",\n",
              " 'respuestar',\n",
              " 'experiencia',\n",
              " '9',\n",
              " '\\u200b',\n",
              " 'Smith',\n",
              " 'graduar',\n",
              " '1964',\n",
              " 'colegio',\n",
              " 'Municipio',\n",
              " 'Deptford',\n",
              " 'dificultad',\n",
              " 'económico',\n",
              " 'atravesar',\n",
              " 'familia',\n",
              " 'comenzar',\n",
              " 'trabajar',\n",
              " 'fábrica',\n",
              " 'bicicleta',\n",
              " '10',\n",
              " '\\u200b',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1967-1973',\n",
              " 'Nueva',\n",
              " 'York',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1967',\n",
              " 'dejar',\n",
              " 'estudio',\n",
              " 'universitario',\n",
              " 'Glassboro',\n",
              " 'State',\n",
              " 'Teachers',\n",
              " 'College',\n",
              " 'mudar',\n",
              " 'ciudad',\n",
              " 'Nueva',\n",
              " 'York',\n",
              " 'Allí',\n",
              " 'mientras',\n",
              " 'trabajar',\n",
              " 'joyería',\n",
              " 'conocer',\n",
              " 'fotógrafo',\n",
              " 'Robert',\n",
              " 'Mapplethorpe',\n",
              " 'fotografía',\n",
              " 'hecho',\n",
              " 'Mapplethorpe',\n",
              " 'convertir',\n",
              " 'portada',\n",
              " 'álbum',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Group',\n",
              " 'seguir',\n",
              " 'ser',\n",
              " 'amigo',\n",
              " 'muerte',\n",
              " 'fotógrafo',\n",
              " '1989',\n",
              " '11',\n",
              " '\\u200b',\n",
              " '1969',\n",
              " 'París',\n",
              " 'hermana',\n",
              " 'comenzar',\n",
              " 'actuar',\n",
              " 'calle',\n",
              " 'hacer',\n",
              " 'arte',\n",
              " 'performance',\n",
              " '7',\n",
              " '\\u200b',\n",
              " 'Smith',\n",
              " 'regresar',\n",
              " 'Nueva',\n",
              " 'York',\n",
              " 'vivir',\n",
              " 'Hotel',\n",
              " 'Chelsea',\n",
              " 'Mapplethorpe',\n",
              " 'frecuentar',\n",
              " 'club',\n",
              " 'moda',\n",
              " 'ciudad',\n",
              " 'CBGB',\n",
              " 'Max',\n",
              " \"'\",\n",
              " 's',\n",
              " 'Kansas',\n",
              " 'City',\n",
              " 'mismo',\n",
              " 'año',\n",
              " 'Smith',\n",
              " 'aparecer',\n",
              " 'Jayne',\n",
              " 'County',\n",
              " 'obra',\n",
              " 'teatro',\n",
              " 'Jackie',\n",
              " 'Curtis',\n",
              " 'Femme',\n",
              " 'Fatale',\n",
              " 'además',\n",
              " 'miembro',\n",
              " 'proyecto',\n",
              " 'poesía',\n",
              " 'St',\n",
              " 'Mark',\n",
              " 'pasar',\n",
              " 'primero',\n",
              " 'año',\n",
              " '70',\n",
              " 'pintar',\n",
              " 'escribir',\n",
              " 'actuar',\n",
              " 'mismo',\n",
              " 'año',\n",
              " 'fotógrafo',\n",
              " 'Loyd',\n",
              " 'Ziff',\n",
              " 'recién',\n",
              " 'graduado',\n",
              " 'Instituto',\n",
              " 'Pratt',\n",
              " 'fotografiar',\n",
              " 'pareja',\n",
              " 'desnudo',\n",
              " 'cuarto',\n",
              " 'Hotel',\n",
              " 'Chelsea',\n",
              " 'aunque',\n",
              " 'año',\n",
              " 'retratado',\n",
              " 'Hall',\n",
              " 'Street',\n",
              " 'dos',\n",
              " 'sesión',\n",
              " 'convertir',\n",
              " 'retrato',\n",
              " 'histórico',\n",
              " 'invaluabl',\n",
              " 'arte',\n",
              " 'norteamericano',\n",
              " 'siglo',\n",
              " 'xx',\n",
              " 'propio',\n",
              " 'Lloyd',\n",
              " 'afirmar',\n",
              " '`',\n",
              " '`',\n",
              " 'pasado',\n",
              " '50',\n",
              " 'año',\n",
              " 'convertido',\n",
              " 'documento',\n",
              " 'época',\n",
              " 'dos',\n",
              " 'artista',\n",
              " 'estadounidense',\n",
              " 'importante',\n",
              " 'joven',\n",
              " 'bello',\n",
              " 'ambicioso',\n",
              " \"''\",\n",
              " '12',\n",
              " '\\u200b',\n",
              " 'fotografía',\n",
              " 'incluido',\n",
              " 'libro',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Just',\n",
              " 'Kids',\n",
              " 'salir',\n",
              " '2009',\n",
              " 'reeditado',\n",
              " '2018',\n",
              " 'publicación',\n",
              " 'desnudo',\n",
              " 'Mapplethorpe',\n",
              " 'petición',\n",
              " 'propio',\n",
              " 'Patti',\n",
              " '13',\n",
              " '\\u200b',\n",
              " '1971',\n",
              " 'hacer',\n",
              " 'performance',\n",
              " 'obra',\n",
              " 'Cowboy',\n",
              " 'Mouth',\n",
              " 'Sam',\n",
              " 'Shepard',\n",
              " '14',\n",
              " '\\u200b',\n",
              " 'colaborar',\n",
              " 'Allen',\n",
              " 'Lanier',\n",
              " 'grupo',\n",
              " 'rock',\n",
              " 'Blue',\n",
              " 'Öyster',\n",
              " 'Cult',\n",
              " 'grabar',\n",
              " 'junto',\n",
              " 'varios',\n",
              " 'canción',\n",
              " 'colaborar',\n",
              " 'Smith',\n",
              " 'incluir',\n",
              " '`',\n",
              " '`',\n",
              " 'Debbie',\n",
              " 'Denise',\n",
              " \"''\",\n",
              " 'poema',\n",
              " '`',\n",
              " '`',\n",
              " 'In',\n",
              " 'Remembrance',\n",
              " 'of',\n",
              " 'Debbie',\n",
              " 'Denise',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Career',\n",
              " 'of',\n",
              " 'Evil',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Fire',\n",
              " 'of',\n",
              " 'Unknown',\n",
              " 'Origin',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'The',\n",
              " 'Revenge',\n",
              " 'of',\n",
              " 'Vera',\n",
              " 'Gemini',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Shooting',\n",
              " 'Shark',\n",
              " \"''\",\n",
              " 'año',\n",
              " 'Smith',\n",
              " 'ejercer',\n",
              " 'periodista',\n",
              " 'musical',\n",
              " 'escribir',\n",
              " 'rock',\n",
              " 'varios',\n",
              " 'publicación',\n",
              " 'revista',\n",
              " 'musical',\n",
              " 'Creem',\n",
              " '15',\n",
              " '\\u200b',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1974-1979',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Group',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1974',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'hacer',\n",
              " 'propio',\n",
              " 'concierto',\n",
              " 'rock',\n",
              " 'inicialmente',\n",
              " 'guitarrista',\n",
              " 'Lenny',\n",
              " 'Kaye',\n",
              " 'posteriormente',\n",
              " 'banda',\n",
              " 'completo',\n",
              " 'formado',\n",
              " 'Kaye',\n",
              " 'bajista',\n",
              " 'Ivan',\n",
              " 'Kral',\n",
              " 'batería',\n",
              " 'Jay',\n",
              " 'Dee',\n",
              " 'Daugherty',\n",
              " 'pianista',\n",
              " 'Richard',\n",
              " 'Sohl',\n",
              " 'Ivan',\n",
              " 'Kral',\n",
              " 'refugiado',\n",
              " 'checoslovaco',\n",
              " 'huido',\n",
              " '1968',\n",
              " 'tras',\n",
              " 'caída',\n",
              " 'Alexander',\n",
              " 'Dubček',\n",
              " 'intento',\n",
              " 'reformista',\n",
              " 'implantar',\n",
              " '`',\n",
              " '`',\n",
              " 'socialismo',\n",
              " 'libertad',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'régimen',\n",
              " 'rostro',\n",
              " 'humano',\n",
              " \"''\",\n",
              " 'Financiados',\n",
              " 'Robert',\n",
              " 'Mapplethorpe',\n",
              " 'banda',\n",
              " 'grabar',\n",
              " 'primero',\n",
              " 'sencillo',\n",
              " '`',\n",
              " '`',\n",
              " 'Hey',\n",
              " 'Joe',\n",
              " 'Piss',\n",
              " 'Factory',\n",
              " \"''\",\n",
              " '1974',\n",
              " 'ser',\n",
              " 'caro',\n",
              " 'versión',\n",
              " 'canción',\n",
              " 'rock',\n",
              " 'escrito',\n",
              " 'Billy',\n",
              " 'Roberts',\n",
              " 'previamente',\n",
              " 'versionado',\n",
              " 'Jimi',\n",
              " 'Hendrix',\n",
              " 'Deep',\n",
              " 'Purple',\n",
              " 'añadido',\n",
              " 'palabra',\n",
              " 'hablado',\n",
              " 'tratar',\n",
              " 'secuestro',\n",
              " 'posterior',\n",
              " 'fuga',\n",
              " 'Patty',\n",
              " 'Hearst',\n",
              " '16',\n",
              " '\\u200b',\n",
              " 'cara',\n",
              " 'B',\n",
              " 'tema',\n",
              " 'hablar',\n",
              " 'frustración',\n",
              " 'ira',\n",
              " 'sentir',\n",
              " 'Smith',\n",
              " 'trabajar',\n",
              " 'línea',\n",
              " 'ensamblado',\n",
              " 'fábrica',\n",
              " 'salvación',\n",
              " 'encontrar',\n",
              " 'libro',\n",
              " 'poesía',\n",
              " 'francés',\n",
              " 'siglo',\n",
              " 'xix',\n",
              " 'Iluminaciones',\n",
              " 'Arthur',\n",
              " 'Rimbaud',\n",
              " 'previamente',\n",
              " 'robado',\n",
              " 'tienda',\n",
              " '10',\n",
              " '\\u200b',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Group',\n",
              " 'firmar',\n",
              " 'sello',\n",
              " 'discográfico',\n",
              " 'Arista',\n",
              " 'Records',\n",
              " 'editar',\n",
              " 'álbum',\n",
              " 'Horses',\n",
              " 'producido',\n",
              " 'John',\n",
              " 'Cale',\n",
              " '1975',\n",
              " 'álbum',\n",
              " 'fusionar',\n",
              " 'punk',\n",
              " 'rock',\n",
              " 'poesía',\n",
              " 'hablado',\n",
              " 'comenzar',\n",
              " 'versión',\n",
              " 'canción',\n",
              " '`',\n",
              " '`',\n",
              " 'Gloria',\n",
              " \"''\",\n",
              " 'Van',\n",
              " 'Morrison',\n",
              " 'palabras',\n",
              " 'Smith',\n",
              " '`',\n",
              " '`',\n",
              " 'Jesús',\n",
              " 'morir',\n",
              " 'pecado',\n",
              " 'alguien',\n",
              " \"''\",\n",
              " 'austero',\n",
              " 'fotografía',\n",
              " 'portado',\n",
              " 'hecho',\n",
              " 'Mapplethorpe',\n",
              " 'convertir',\n",
              " 'imagen',\n",
              " 'clásico',\n",
              " 'rock',\n",
              " '17',\n",
              " '\\u200b',\n",
              " 'Mientras',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Group',\n",
              " 'girar',\n",
              " 'Unidos',\n",
              " 'Europa',\n",
              " 'popularidad',\n",
              " 'punk',\n",
              " 'comenzar',\n",
              " 'aumentar',\n",
              " 'sonido',\n",
              " 'crudo',\n",
              " 'segundo',\n",
              " 'álbum',\n",
              " 'Radio',\n",
              " 'Ethiopia',\n",
              " 'reflejar',\n",
              " 'cambio',\n",
              " 'recibir',\n",
              " 'uno',\n",
              " 'crítica',\n",
              " 'bastante',\n",
              " 'mediocre',\n",
              " 'aun',\n",
              " 'así',\n",
              " 'varios',\n",
              " 'canción',\n",
              " 'álbum',\n",
              " 'sobrevivido',\n",
              " 'paso',\n",
              " 'tiempo',\n",
              " 'Smith',\n",
              " 'aún',\n",
              " 'tocar',\n",
              " 'directo',\n",
              " 'hoy',\n",
              " 'día',\n",
              " '18',\n",
              " '\\u200b',\n",
              " '23',\n",
              " 'enero',\n",
              " '1977',\n",
              " 'mientras',\n",
              " 'encontrar',\n",
              " 'gira',\n",
              " 'promocionar',\n",
              " 'álbum',\n",
              " 'Smith',\n",
              " 'accidentar',\n",
              " 'mientras',\n",
              " 'bailar',\n",
              " 'caer él',\n",
              " 'tarima',\n",
              " 'Tampa',\n",
              " 'Florida',\n",
              " 'caer',\n",
              " 'cemento',\n",
              " 'fosa',\n",
              " 'orquesto',\n",
              " 'fracturar él',\n",
              " 'varios',\n",
              " 'vértebra',\n",
              " 'cervical',\n",
              " '19',\n",
              " '\\u200b',\n",
              " 'accidente',\n",
              " 'obligar',\n",
              " 'descansar',\n",
              " 'hacer',\n",
              " 'rehabilitación',\n",
              " 'tiempo',\n",
              " 'reposo',\n",
              " 're-energizar él',\n",
              " 'reorganizar',\n",
              " 'vida',\n",
              " 'después',\n",
              " 'recuperación',\n",
              " 'Patti',\n",
              " 'Smith',\n",
              " 'Group',\n",
              " 'editar',\n",
              " 'dos',\n",
              " 'álbum',\n",
              " 'finalizar',\n",
              " 'año',\n",
              " '70',\n",
              " 'Easter',\n",
              " '1978',\n",
              " 'contener',\n",
              " 'sencillo',\n",
              " '`',\n",
              " '`',\n",
              " 'Because',\n",
              " 'the',\n",
              " 'Night',\n",
              " \"''\",\n",
              " 'coescrito',\n",
              " 'Bruce',\n",
              " 'Springsteen',\n",
              " 'álbum',\n",
              " 'éxito',\n",
              " 'comercial',\n",
              " 'Wave',\n",
              " '1979',\n",
              " 'menos',\n",
              " 'exitoso',\n",
              " 'aunque',\n",
              " 'canción',\n",
              " '`',\n",
              " '`',\n",
              " 'Frederick',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Dancing',\n",
              " 'Barefoot',\n",
              " \"''\",\n",
              " 'radiada',\n",
              " '20',\n",
              " '\\u200b',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1980-1995',\n",
              " 'Boda',\n",
              " 'hijos',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " 'lanzar',\n",
              " 'Wave',\n",
              " 'Smith',\n",
              " 'ahora',\n",
              " 'separado',\n",
              " 'Allen',\n",
              " 'Lanier',\n",
              " 'conocer',\n",
              " 'Fred',\n",
              " '`',\n",
              " '`',\n",
              " 'Sonic',\n",
              " \"''\",\n",
              " 'Smith',\n",
              " 'exguitarrista',\n",
              " 'banda',\n",
              " 'rock',\n",
              " 'Detroit',\n",
              " 'Míchigan',\n",
              " 'MC5',\n",
              " 'aquel',\n",
              " 'momento',\n",
              " 'formado',\n",
              " 'banda',\n",
              " 'Sonic',\n",
              " \"'\",\n",
              " 's',\n",
              " 'Rendezvous',\n",
              " 'Band',\n",
              " 'adorar',\n",
              " 'poesía',\n",
              " '`',\n",
              " '`',\n",
              " 'Dancing',\n",
              " 'Barefoot',\n",
              " \"''\",\n",
              " '`',\n",
              " '`',\n",
              " 'Frederick',\n",
              " \"''\",\n",
              " 'álbum',\n",
              " 'Wave',\n",
              " 'ambos',\n",
              " 'dedicado',\n",
              " '21',\n",
              " '\\u200b',\n",
              " 'unión',\n",
              " 'suscitar',\n",
              " 'broma',\n",
              " 'hecho',\n",
              " 'solo',\n",
              " 'casar',\n",
              " 'tener',\n",
              " 'cambiar él',\n",
              " 'apellido',\n",
              " '22',\n",
              " '\\u200b',\n",
              " 'hijo',\n",
              " 'Jackson',\n",
              " 'nacido',\n",
              " '1982',\n",
              " 'adelante',\n",
              " 'hija',\n",
              " 'Jesse',\n",
              " 'nacido',\n",
              " '1987',\n",
              " 'mayor',\n",
              " 'parte',\n",
              " 'año',\n",
              " '80',\n",
              " 'Patti',\n",
              " 'retirado',\n",
              " 'escena',\n",
              " 'musical',\n",
              " 'vivir',\n",
              " 'familia',\n",
              " 'St',\n",
              " 'Clair',\n",
              " 'Shores',\n",
              " 'norte',\n",
              " 'Detroit',\n",
              " 'editar',\n",
              " 'junio',\n",
              " '1988',\n",
              " 'álbum',\n",
              " 'Dream',\n",
              " 'of',\n",
              " 'Life',\n",
              " 'incluir',\n",
              " 'canción',\n",
              " '`',\n",
              " '`',\n",
              " 'People',\n",
              " 'Have',\n",
              " 'the',\n",
              " 'Power',\n",
              " \"''\",\n",
              " 'Fred',\n",
              " 'Smith',\n",
              " 'morir',\n",
              " '4',\n",
              " 'noviembre',\n",
              " '1994',\n",
              " 'tiempo',\n",
              " 'Patti',\n",
              " 'afrontar',\n",
              " 'inesperado',\n",
              " 'muerte',\n",
              " 'hermano',\n",
              " 'Todd',\n",
              " 'teclista',\n",
              " 'banda',\n",
              " 'Richard',\n",
              " 'Sohl',\n",
              " '7',\n",
              " '\\u200b',\n",
              " 'cumplir',\n",
              " 'hijo',\n",
              " '14',\n",
              " 'año',\n",
              " 'Smith',\n",
              " 'decidir',\n",
              " 'volver',\n",
              " 'Nueva',\n",
              " 'York',\n",
              " 'amigo',\n",
              " 'Michael',\n",
              " 'Stipe',\n",
              " 'R.E.M',\n",
              " 'Allen',\n",
              " 'Ginsberg',\n",
              " 'conocido',\n",
              " 'primero',\n",
              " 'año',\n",
              " 'Nueva',\n",
              " 'York',\n",
              " 'instar',\n",
              " 'volver',\n",
              " 'hacer',\n",
              " 'gira',\n",
              " 'recuperar él',\n",
              " 'impacto',\n",
              " 'último',\n",
              " 'acontecimiento',\n",
              " 'embarcar',\n",
              " 'pequeño',\n",
              " 'gira',\n",
              " 'junto',\n",
              " 'Bob',\n",
              " 'Dylan',\n",
              " 'diciembre',\n",
              " '1995',\n",
              " 'captado',\n",
              " 'libro',\n",
              " 'fotográfico',\n",
              " 'Michael',\n",
              " 'Stipe',\n",
              " '14',\n",
              " '\\u200b',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1996-2003',\n",
              " 'Retorno',\n",
              " '=',\n",
              " '=',\n",
              " '=',\n",
              " '1996',\n",
              " 'Smith',\n",
              " 'volver',\n",
              " 'trabajar',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}