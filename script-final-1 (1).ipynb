{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nimport re\nimport os\nimport warnings\n\n#basic tools \nimport os\nimport warnings\n\n#tuning hyperparameters\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \n\n#graph, plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#building models\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nimport time\nimport sys\n\n#metrics \nfrom sklearn.metrics import roc_curve\nimport shap\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Leo todos los datasets menos el de censo ya que da un mejor resultado en el cross validation pero no en el leaderboard público."},{"metadata":{"trusted":true},"cell_type":"code","source":"rcc_train = pd.read_csv(\"/kaggle/input/interbank20/rcc_train.csv\")\nse_train = pd.read_csv(\"/kaggle/input/interbank20/se_train.csv\", index_col=\"key_value\")\n#censo_train = pd.read_csv(\"/kaggle/input/interbank20/censo_train.csv\", index_col=\"key_value\")\nsunat_train = pd.read_csv(\"/kaggle/input/interbank20/sunat_train.csv\")\ny_train = pd.read_csv(\"/kaggle/input/interbank20/y_train.csv\", index_col=\"key_value\").target\n\nrcc_test= pd.read_csv(\"/kaggle/input/interbank20/rcc_test.csv\")\nse_test= pd.read_csv(\"/kaggle/input/interbank20/se_test.csv\", index_col=\"key_value\")\n#censo_test= pd.read_csv(\"/kaggle/input/interbank20/censo_test.csv\", index_col=\"key_value\")\nsunat_test = pd.read_csv(\"/kaggle/input/interbank20/sunat_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discretizo la variable condición."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [-1, 0, 10, 20, 30, 60, 90, 180, 360, 720, float(\"inf\")]\nrcc_train[\"condicion\"] = pd.cut(rcc_train.condicion, bins)\nrcc_test[\"condicion\"] = pd.cut(rcc_test.condicion, bins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creación de la función usada en el benchmark para hacer la cuenta, suma, maximo y minimo de los saldos por cada una de las otras variables:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def makeCt(df, c, aggfunc=sum):\n    try:\n        ct = pd.crosstab(df.key_value, df[c].fillna(\"N/A\"), values=df.saldo, aggfunc=aggfunc)\n    except:\n        ct = pd.crosstab(df.key_value, df[c], values=df.saldo, aggfunc=aggfunc)\n    ct.columns = [f\"{c}_{aggfunc.__name__}_{v}\" for v in ct.columns]\n    return ct","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Desarrollo de las nuevas variables con la función anterior:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = []\ntest = []\naggfuncs = [len, sum, min, max]\nfor c in rcc_train.drop([\"codmes\", \"key_value\", \"saldo\"], axis=1):\n    print(\"haciendo\", c)\n    train.extend([makeCt(rcc_train, c, aggfunc) for aggfunc in aggfuncs])\n    test.extend([makeCt(rcc_test, c, aggfunc) for aggfunc in aggfuncs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat(train, axis=1)\ntest = pd.concat(test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uno los datasets \"rcc\" con los \"se\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.join(se_train)\ntest = test.join(se_test)\n\nimport gc\n\ndel se_train, se_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ANALISIS DATASET SUNAT**\n\n"},{"metadata":{},"cell_type":"markdown","source":"Elimino las lineas que están duplicadas identicamente."},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train=sunat_train.drop_duplicates()\nsunat_test=sunat_test.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Discretizo las variables fecalta y fecbaja."},{"metadata":{"trusted":true},"cell_type":"code","source":"bins = [-1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5]\nsunat_train[\"fecalta\"] = pd.cut(sunat_train.fecalta, bins)\nsunat_test[\"fecalta\"] = pd.cut(sunat_test.fecalta, bins)\nbins = [-5,-4.5,-4,-3.5,-3,-2.5,-2,-1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5]\nsunat_train[\"fecbaja\"] = pd.cut(sunat_train.fecbaja, bins)\nsunat_test[\"fecbaja\"] = pd.cut(sunat_test.fecbaja, bins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creo una función similar a la creada al principio para \"rcc\", pero que cuente la cantidad de key_values iguales que hay para cada valor \nde una variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"def makeCt_1(df, c, aggfunc=len):\n    try:\n        ct = pd.crosstab(df.key_value, df[c].fillna(\"N/A\"), values=df.key_value, aggfunc=aggfunc)\n    except:\n        ct = pd.crosstab(df.key_value, df[c], values=df.key_value, aggfunc=aggfunc)\n    ct.columns = [f\"{c}_{v}\" for v in ct.columns]\n    return ct","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creo un ciclo for que aplique la función anterior a cada una de las variables y entrene un LGBM para ver qué variables suman y cuales no.\nHago esto porque Kaggle se queda sin memoria si utilizo todos los atributos directamente.\nExcluyo \"ubigeo\" y \"cargorele\" porque se queda sin memoria al intentar hacerlo. "},{"metadata":{},"cell_type":"markdown","source":"El mismo modelo LGBM sin ninguna de las variables de \"sunat\" da un auc de 0.8141, por lo tanto me voy a quedar con las variables que, al ser\nincluidas en el modelo, den un AUC mayor."},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train_1 = sunat_train\nsunat_test_1 = sunat_test\n\ntrain_1=train\ntest_1=test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel rcc_train, rcc_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ParameterGrid\nfor c in ['condiciondomicilio', 'estadocontribuyente',\n       'codvia', 'codzona', 'contabilidad', 'facturacion', 'domiciliado',\n       'comercioexterior', 'codentidadtributo', 'estadotributo','fecalta','fecbaja']:\n    print(\"haciendo\", c)\n    sunat_train_3 = []\n    sunat_test_3 = []\n    sunat_train_3.extend([makeCt_1(sunat_train_1, c)])\n    sunat_test_3.extend([makeCt_1(sunat_test_1, c)])\n    sunat_train_3 = pd.concat(sunat_train_3, axis=1)\n    sunat_test_3 = pd.concat(sunat_test_3, axis=1)\n    test = pd.merge(test_1,sunat_test_3, on= 'key_value' ,how='left')\n    del sunat_test_3\n    gc.collect()\n    train = pd.merge(train_1,sunat_train_3, on= 'key_value' ,how='left')\n    del sunat_train_3\n    gc.collect()\n    keep_cols = list(set(train.columns).intersection(set(test.columns)))\n    train = train[keep_cols]\n    test = test[keep_cols]\n    len(set(train.columns) - set(test.columns)) , len(set(test.columns) - set(train.columns))\n    test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))\n    train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_-]+', '', x))\n    folds = [train.index[t] for t, v in KFold(5).split(train)]\n    params = ParameterGrid({\"min_child_samples\": [1000], \"boosting_type\": [\"gbdt\"]})\n    best_score = 0\n    best_probs = []\n    for param in params:\n        test_probs = []\n        train_probs = []\n        p  = \"///\".join([f\"{k}={v}\" for k, v in param.items()])\n        print(\"*\"*10, p, \"*\"*10)\n        for i, idx in enumerate(folds):\n            Xt = train.loc[idx]\n            yt = y_train.loc[Xt.index]\n\n            Xv = train.drop(Xt.index)\n            yv = y_train.loc[Xv.index]\n\n            learner = LGBMClassifier(n_estimators=1000, **param)\n            learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n                        eval_set=[(Xt, yt), (Xv, yv)], verbose=False)\n            test_probs.append(pd.Series(learner.predict_proba(test)[:, -1], index=test.index, name=\"fold_\" + str(i)))\n            train_probs.append(pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index, name=\"probs\"))\n\n        test_probs = pd.concat(test_probs, axis=1).mean(axis=1)\n        train_probs = pd.concat(train_probs)\n        score = roc_auc_score(y_train, train_probs.loc[y_train.index])\n        print(f\"roc auc estimado para {p} con {c}: {score}\")\n        if score > best_score:\n            print(\"*\"*10, f\"{p} es el nuevo mejor modelo\", \"*\"*10)\n            best_score = score\n            best_probs = test_probs\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En el ciclo anterior veo que todas agregan valor excepto por \"codvia\". Por lo tanto las agrego como categoricas, contando la cantidad de key_values por cada valor de variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train_2 = []\nsunat_test_2 = []\nfor c in [\"tipcontribuyente\",\"tippersona\",\"ciiu\",\"condiciondomicilio\",\"estadocontribuyente\",\"codzona\",\"contabilidad\",\"facturacion\",\"domiciliado\",\"comercioexterior\",\"codentidadtributo\",\"estadotributo\",\"fecalta\",\"fecbaja\"]:\n    print(\"haciendo\", c)\n    sunat_train_2.extend([makeCt_1(sunat_train, c)])\n    sunat_test_2.extend([makeCt_1(sunat_test, c)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sunat_train_2 = pd.concat(sunat_train_2, axis=1)\nsunat_test_2 = pd.concat(sunat_test_2, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Uno los datasets train y test con las nuevas variables creadas de sunat:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train_1,sunat_train_2, on= 'key_value' ,how='left')\ntest = pd.merge(test_1,sunat_test_2, on= 'key_value' ,how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sunat_train_2\ndel sunat_test_2\ndel test_1\ndel train_1\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('test_complete.csv')\ntrain.to_csv('train_complete.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***************************************************************************************************************************************"},{"metadata":{},"cell_type":"markdown","source":"**MODELO**: Continúa en el Script FINAL_2"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}